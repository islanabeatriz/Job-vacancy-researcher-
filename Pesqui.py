import requests
from bs4 import BeautifulSoup
import pandas as pd

headers = {
    "User-Agent": "Mozilla/5.0 (X11; Linux x86_64) AppleWebKit/537.36 "
                  "(KHTML, like Gecko) Chrome/115.0 Safari/537.36"
}

base_url = "https://www.linkedin.com/jobs-guest/jobs/api/seeMoreJobPostings/search"
params = {
    "keywords": "Testador de QA",
    "location": "Brazil",
    "start": 0
}

all_jobs = []

# Vamos buscar at√© 100 vagas (4 p√°ginas = 0,25,50,75)
for start in range(0, 100, 25):
    params["start"] = start
    response = requests.get(base_url, headers=headers, params=params)

    if response.status_code != 200:
        print(f"‚ö†Ô∏è Erro na p√°gina {start}: {response.status_code}")
        break

    soup = BeautifulSoup(response.text, "html.parser")
    jobs = soup.find_all("li")

    if not jobs:  # Se n√£o houver mais vagas, parar o loop
        print("üö´ N√£o h√° mais vagas dispon√≠veis.")
        break

    for job in jobs:
        try:
            title = job.find("h3", class_="base-search-card__title").text.strip()
            company = job.find("h4", class_="base-search-card__subtitle").text.strip()
            link = job.find("a", class_="base-card__full-link")["href"]

            all_jobs.append({
                "T√≠tulo": title,
                "Empresa": company,
                "Link": link
            })
        except Exception:
            pass

# Salvar em CSV
df = pd.DataFrame(all_jobs)
df.to_csv("linkedin_jobs.csv", index=False, encoding="utf-8-sig")

print(f" Coletadas {len(all_jobs)} vagas e salvas em linkedin_jobs.csv")
